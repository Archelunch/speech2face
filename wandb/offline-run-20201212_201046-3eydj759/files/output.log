
  | Name        | Type    | Params
----------------------------------------
0 | res_to_glow | Decoder | 202 M 
1 | glow        | Glow    | 267 M 
Validation sanity check: 0it [00:00, ?it/s]SHAPE torch.Size([12, 384, 2, 2]) torch.Size([12, 49152])
/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/functional.py:2352: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn("reduction: 'mean' divides the total loss by both the batch size and the support size."
Traceback (most recent call last):
  File "train.py", line 78, in <module>
    main()
  File "train.py", line 74, in main
    trainer.fit(decoder_light)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 444, in fit
    results = self.accelerator_backend.train()
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/accelerators/cpu_accelerator.py", line 57, in train
    results = self.train_or_test()
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 74, in train_or_test
    results = self.trainer.train()
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 466, in train
    self.run_sanity_check(self.get_model())
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 658, in run_sanity_check
    _, eval_results = self.run_evaluation(test_mode=False, max_batches=self.num_sanity_val_batches)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 578, in run_evaluation
    output = self.evaluation_loop.evaluation_step(test_mode, batch, batch_idx, dataloader_idx)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/evaluation_loop.py", line 171, in evaluation_step
    output = self.trainer.accelerator_backend.validation_step(args)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/accelerators/cpu_accelerator.py", line 73, in validation_step
    output = self.trainer.model.validation_step(*args)
  File "/home/mvpavlukhin/speech2face/decoder_lighhtning.py", line 88, in validation_step
    loss1 = torch.nn.KLDivLoss()(z_image, z_sound)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 379, in forward
    return F.kl_div(input, target, reduction=self.reduction, log_target=self.log_target)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/functional.py", line 2362, in kl_div
    reduced = torch.kl_div(input, target, reduction_enum, log_target=log_target)
RuntimeError: The size of tensor a (49152) must match the size of tensor b (2) at non-singleton dimension 3
