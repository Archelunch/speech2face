
  | Name        | Type    | Params
----------------------------------------
0 | res_to_glow | Decoder | 7 M   
1 | glow        | Glow    | 267 M 
Validation sanity check: 0it [00:00, ?it/s]/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/functional.py:2352: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn("reduction: 'mean' divides the total loss by both the batch size and the support size."
Validation sanity check:  50%|█████     | 1/2 [00:17<00:17, 17.44s/it]Validation sanity check: 100%|██████████| 2/2 [00:33<00:00, 17.08s/it]                                                                      Training: 0it [00:00, ?it/s]Training:   0%|          | 0/1526312 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1526312 [00:00<?, ?it/s] /home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0
Please use self.log(...) inside the lightningModule instead.

# log on a step or aggregate epoch metric to the logger and/or progress bar
# (inside LightningModule)
self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)
  warnings.warn(*args, **kwargs)
Epoch 0:   0%|          | 1/1526312 [00:19<8238:41:27, 19.43s/it]Epoch 0:   0%|          | 1/1526312 [00:19<8239:04:22, 19.43s/it, loss=nan, v_num=70f9]Epoch 0:   0%|          | 2/1526312 [00:34<7405:20:25, 17.47s/it, loss=nan, v_num=70f9]Epoch 0:   0%|          | 2/1526312 [00:34<7405:28:58, 17.47s/it, loss=nan, v_num=70f9]Epoch 0:   0%|          | 3/1526312 [00:49<6928:16:33, 16.34s/it, loss=nan, v_num=70f9]Epoch 0:   0%|          | 3/1526312 [00:49<6928:22:02, 16.34s/it, loss=nan, v_num=70f9]Epoch 0:   0%|          | 4/1526312 [01:04<6834:34:07, 16.12s/it, loss=nan, v_num=70f9]Epoch 0:   0%|          | 4/1526312 [01:04<6834:36:33, 16.12s/it, loss=nan, v_num=70f9]/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/ranger/ranger.py:138: UserWarning: This overload of addcmul_ is deprecated:
	addcmul_(Number value, Tensor tensor1, Tensor tensor2)
Consider using one of the following signatures instead:
	addcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629395347/work/torch/csrc/utils/python_arg_parser.cpp:766.)
  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
Epoch 0:   0%|          | 5/1526312 [01:04<5473:24:03, 12.91s/it, loss=nan, v_num=70f9]/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
  warnings.warn(*args, **kwargs)
Epoch 0: val_loss reached -112400152.00000 (best -112400152.00000), saving model to /home/mvpavlukhin/speech2face/output/epoch=0.ckpt as top 1
Traceback (most recent call last):
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 493, in train
    self.train_loop.run_training_epoch()
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 561, in run_training_epoch
    batch_output = self.run_training_batch(batch, batch_idx, dataloader_idx)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 700, in run_training_batch
    self.training_step_and_backward(split_batch, batch_idx, opt_idx, optimizer, self.trainer.hiddens)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 813, in training_step_and_backward
    result = self.training_step(split_batch, batch_idx, opt_idx, hiddens)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 320, in training_step
    training_step_output = self.trainer.accelerator_backend.training_step(args)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/accelerators/cpu_accelerator.py", line 65, in training_step
    output = self.trainer.model.training_step(*args)
  File "/home/mvpavlukhin/speech2face/decoder_lighhtning.py", line 67, in training_step
    z_image,_,_ = self.glow(x=image, reverse=False)  # from image to z space
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/mvpavlukhin/speech2face/glow/model.py", line 281, in forward
    return self.normal_flow(x, y_onehot)
  File "/home/mvpavlukhin/speech2face/glow/model.py", line 288, in normal_flow
    z, objective = self.flow(x, logdet=logdet, reverse=False)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/mvpavlukhin/speech2face/glow/model.py", line 185, in forward
    return self.encode(input, logdet)
  File "/home/mvpavlukhin/speech2face/glow/model.py", line 189, in encode
    z, logdet = layer(z, logdet, reverse=False)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/mvpavlukhin/speech2face/glow/model.py", line 80, in forward
    return self.normal_flow(input, logdet)
  File "/home/mvpavlukhin/speech2face/glow/model.py", line 88, in normal_flow
    z, logdet = self.actnorm(input, logdet=logdet, reverse=False)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/mvpavlukhin/speech2face/glow/modules.py", line 139, in forward
    input, logdet = self._scale(input, logdet, reverse)
  File "/home/mvpavlukhin/speech2face/glow/modules.py", line 110, in _scale
    input = input * torch.exp(self.logs)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train.py", line 78, in <module>
    main()
  File "train.py", line 74, in main
    trainer.fit(decoder_light)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 444, in fit
    results = self.accelerator_backend.train()
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/accelerators/cpu_accelerator.py", line 57, in train
    results = self.train_or_test()
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 74, in train_or_test
    results = self.trainer.train()
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 532, in train
    self.train_loop.on_train_end()
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 190, in on_train_end
    self.check_checkpoint_callback(should_save=True, is_last=True)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 220, in check_checkpoint_callback
    [c.on_validation_end(self.trainer, model) for c in checkpoint_callbacks]
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py", line 220, in <listcomp>
    [c.on_validation_end(self.trainer, model) for c in checkpoint_callbacks]
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 186, in on_validation_end
    self.save_checkpoint(trainer, pl_module)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 232, in save_checkpoint
    self._save_top_k_checkpoints(monitor_candidates, trainer, pl_module, epoch, filepath)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 534, in _save_top_k_checkpoints
    self._update_best_and_save(filepath, current, epoch, trainer, pl_module)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 583, in _update_best_and_save
    self._save_model(filepath, trainer, pl_module)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py", line 333, in _save_model
    self.save_function(filepath, self.save_weights_only)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/properties.py", line 207, in save_checkpoint
    self.checkpoint_connector.save_checkpoint(filepath, weights_only)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 394, in save_checkpoint
    atomic_save(checkpoint, filepath)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py", line 60, in atomic_save
    torch.save(checkpoint, bytesbuffer, _use_new_zipfile_serialization=False)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/serialization.py", line 366, in save
    _legacy_save(obj, opened_file, pickle_module, pickle_protocol)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/serialization.py", line 431, in _legacy_save
    pickler.dump(obj)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/serialization.py", line 412, in persistent_id
    obj.size(),
KeyboardInterrupt
