
  | Name        | Type    | Params
----------------------------------------
0 | res_to_glow | Decoder | 202 M 
1 | glow        | Glow    | 267 M 
Validation sanity check: 0it [00:00, ?it/s]
Z image  torch.Size([12, 384, 2, 2]) Z sound  torch.Size([12, 192, 16, 16]) SHAPE IMG torch.Size([12, 3, 128, 128])
Traceback (most recent call last):
  File "train.py", line 78, in <module>
    main()
  File "train.py", line 74, in main
    trainer.fit(decoder_light)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 444, in fit
    results = self.accelerator_backend.train()
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/accelerators/cpu_accelerator.py", line 57, in train
    results = self.train_or_test()
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 74, in train_or_test
    results = self.trainer.train()
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 466, in train
    self.run_sanity_check(self.get_model())
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 658, in run_sanity_check
    _, eval_results = self.run_evaluation(test_mode=False, max_batches=self.num_sanity_val_batches)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 578, in run_evaluation
    output = self.evaluation_loop.evaluation_step(test_mode, batch, batch_idx, dataloader_idx)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/trainer/evaluation_loop.py", line 171, in evaluation_step
    output = self.trainer.accelerator_backend.validation_step(args)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/pytorch_lightning/accelerators/cpu_accelerator.py", line 73, in validation_step
    output = self.trainer.model.validation_step(*args)
  File "/home/mvpavlukhin/speech2face/decoder_lighhtning.py", line 86, in validation_step
    image_from_sound = self.glow(z=z_sound, reverse=True)  # from z space (resemblyzer) to image
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/mvpavlukhin/speech2face/glow/model.py", line 279, in forward
    return self.reverse_flow(z, y_onehot, temperature)
  File "/home/mvpavlukhin/speech2face/glow/model.py", line 308, in reverse_flow
    x = self.flow(z, temperature=temperature, reverse=True)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/mvpavlukhin/speech2face/glow/model.py", line 183, in forward
    return self.decode(input, temperature)
  File "/home/mvpavlukhin/speech2face/glow/model.py", line 199, in decode
    z, logdet = layer(z, logdet=0, reverse=True)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/mvpavlukhin/speech2face/glow/model.py", line 82, in forward
    return self.reverse_flow(input, logdet)
  File "/home/mvpavlukhin/speech2face/glow/model.py", line 114, in reverse_flow
    z2 = z2 - self.block(z1)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/mvpavlukhin/speech2face/glow/modules.py", line 213, in forward
    x = self.conv(input)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 419, in forward
    return self._conv_forward(input, self.weight)
  File "/home/mvpavlukhin/.conda/envs/speech2face/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 415, in _conv_forward
    return F.conv2d(input, weight, self.bias, self.stride,
RuntimeError: Given groups=1, weight of size [512, 192, 3, 3], expected input[12, 96, 16, 16] to have 192 channels, but got 96 channels instead
